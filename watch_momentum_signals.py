# -*- coding: utf-8 -*-
"""
watch_momentum_signals.py (GitHub Actions å¯¾å¿œãƒ»å®‰å…¨ç‰ˆ)

- watchlist.csv ã‚’èª­ã¿è¾¼ã¿ã€å„éŠ˜æŸ„ã«ã¤ã„ã¦ä»¥ä¸‹ã® â€œãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æ¡ä»¶â€ ã‚’è©•ä¾¡
  1) ROC(ROC_PERIOD) > 0
  2) å‡ºæ¥é«˜: ç›´è¿‘20æ—¥å¹³å‡(å‰æ—¥ã¾ã§)Ã—VOLUME_MULT ã¨ã®å€ç‡æ¡ä»¶
              ã¨ æ˜¨æ—¥ã¾ã§60æœ¬ã®å‡ºæ¥é«˜åˆ†ä½ VOL_QUANTILE (ä¾‹: 0.80=80%) ã®
              OR / AND åˆ¤å®š (VOL_COND_MODE)
     ã•ã‚‰ã« MIN_TURNOVER_JPYï¼ˆå£²è²·ä»£é‡‘ã—ãã„å€¤ï¼‰ã‚’æº€ãŸã™å ´åˆã®ã¿æœ‰åŠ¹
  3) 20æ—¥é«˜å€¤(å‰æ—¥ã¾ã§) ã‚’ã€Œçµ‚å€¤ã€ã§ä¸ŠæŠœã‘

- Slack ã¸é€šçŸ¥ï¼ˆIncoming Webhookï¼‰
- ã€ŒğŸ†•åˆå›(å‰å›: YYYY-MM-DDã€çµŒé: Nå–¶æ¥­æ—¥)ã€ã‚¿ã‚°ã‚’ã‚¿ã‚¤ãƒˆãƒ«ç›´ä¸‹ã«è¡¨ç¤º
  * å‰å›ãƒ’ãƒƒãƒˆæ—¥ã¯ notified_state.json ã® last_hits[symbol] ã« â€œå–å¼•æ—¥â€ ã‚’ä¿å­˜
  * GitHub Actions ã¯ã‚¨ãƒ•ã‚§ãƒ¡ãƒ©ãƒ«ç’°å¢ƒã®ãŸã‚ã€ã“ã®JSONã¯æ¯å›ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™
    ï¼ˆæ°¸ç¶šåŒ–ã—ãŸã„å ´åˆã¯ Artifacts ã‚„ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒŸãƒƒãƒˆç­‰ã‚’ã”æ¤œè¨ãã ã•ã„ï¼‰

ç’°å¢ƒå¤‰æ•°ï¼ˆGitHub Secrets ã§è¨­å®šæ¨å¥¨ï¼‰
  SLACK_WEBHOOK_URL      : Slack Incoming Webhook ã®URL
  VOLUME_MULT            : å‡ºæ¥é«˜å€ç‡ (default 1.5)
  VOL_QUANTILE           : åˆ†ä½ï¼ˆ0.0ã€œ1.0, default 0.80ï¼‰
  VOL_COND_MODE          : "OR" or "AND"ï¼ˆå€ç‡ã¨åˆ†ä½ã®çµåˆæ–¹æ³•, default "OR"ï¼‰
  MIN_TURNOVER_JPY       : æœ€ä½å£²è²·ä»£é‡‘ï¼ˆå††, default 0ï¼‰
  ROC_PERIOD             : ROCã®æœŸé–“ (default 14)
  FIRST_SEEN_BD          : â€œåˆå›â€ã¨è¡¨ç¤ºã™ã‚‹å–¶æ¥­æ—¥ã‚®ãƒ£ãƒƒãƒ— (default 10)
  TZ                     : ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ï¼ˆ"Asia/Tokyo" / "JST" ãªã©ï¼‰
"""

import os
import sys
import json
import time
import traceback
from datetime import datetime, timedelta, timezone
from pathlib import Path

import numpy as np
import pandas as pd
import requests

# ========= ç’°å¢ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =========
def _clean_env(val: str | None) -> str | None:
    if val is None:
        return None
    return val.split("#", 1)[0].strip()

SLACK_WEBHOOK_URL = _clean_env(os.getenv("SLACK_WEBHOOK_URL", "")) or ""

_TZ = _clean_env(os.getenv("TZ", "Asia/Tokyo")) or "Asia/Tokyo"
JST = timezone(timedelta(hours=9)) if _TZ in ("Asia/Tokyo", "JST") else timezone.utc

def _f(k, default):
    try:
        v = _clean_env(os.getenv(k, str(default)))
        return float(v if v not in (None, "") else default)
    except Exception:
        return float(default)

def _i(k, default):
    try:
        v = _clean_env(os.getenv(k, str(default)))
        return int(v if v not in (None, "") else default)
    except Exception:
        return int(default)

VOLUME_MULT       = _f("VOLUME_MULT", 1.5)
VOL_QUANTILE      = _f("VOL_QUANTILE", 0.80)         # 0.0ã€œ1.0
VOL_COND_MODE     = (_clean_env(os.getenv("VOL_COND_MODE", "OR")) or "OR").upper()
if VOL_COND_MODE not in ("OR", "AND"):
    VOL_COND_MODE = "OR"
MIN_TURNOVER_JPY  = _f("MIN_TURNOVER_JPY", 0)
ROC_PERIOD        = _i("ROC_PERIOD", 14)
FIRST_SEEN_BD     = _i("FIRST_SEEN_BD", 10)

REQUEST_TIMEOUT   = 12
LOOKBACK_DAYS     = 240

SCRIPT_DIR = Path(__file__).resolve().parent
NOTIFIED_STATE_FILE = "notified_state.json"

# ========= ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª =========
try:
    import yfinance as yf
except Exception:
    yf = None

# ========= Slacké€šçŸ¥ =========
def notify_slack(text: str):
    try:
        if not SLACK_WEBHOOK_URL:
            print("[WARN] Slack Webhook æœªè¨­å®š\n" + text)
            return
        url = SLACK_WEBHOOK_URL.strip().strip('"').strip("'")
        res = requests.post(url, json={"text": text}, timeout=REQUEST_TIMEOUT)
        if res.status_code != 200:
            print(f"[SLACK] {datetime.now(JST)} status={res.status_code} body={res.text[:200]}")
        else:
            print(f"[SLACK] {datetime.now(JST)} OK len={len(text)}")
    except Exception as e:
        print(f"[SLACK EXC] {e}\n{text}")

# ========= JSONãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå‰å›ãƒ’ãƒƒãƒˆä¿å­˜ï¼‰ =========
def _load_json(path: Path) -> dict:
    try:
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {}

def _save_json(path: Path, data: dict):
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def _get_prev_hit_date(symbol: str):
    st_path = SCRIPT_DIR / NOTIFIED_STATE_FILE
    st = _load_json(st_path)
    if isinstance(st.get("last_hits"), dict):
        iso = st["last_hits"].get(symbol)
        if iso:
            try:
                return datetime.strptime(iso[:10], "%Y-%m-%d").date()
            except Exception:
                pass
    # ï¼ˆæ—§å½¢å¼ã‚µãƒãƒ¼ãƒˆã‚’çœç•¥ï¼šActions ã§ã¯æ°¸ç¶šåŒ–ã—ãªã„ãŸã‚é€šå¸¸ä¸è¦ï¼‰
    return None

def _update_last_hit(symbol: str, trade_date):
    st_path = SCRIPT_DIR / NOTIFIED_STATE_FILE
    st = _load_json(st_path)
    if "last_hits" not in st or not isinstance(st["last_hits"], dict):
        st["last_hits"] = {}
    st["last_hits"][symbol] = trade_date.isoformat()
    _save_json(st_path, st)

def build_first_seen_tag(symbol: str, hit_trade_date) -> str:
    """
    ç›´è¿‘ FIRST_SEEN_BD å–¶æ¥­æ—¥ä»¥ä¸Šã‚ã‘ã°ã€ŒğŸ†•åˆå›(å‰å›: YYYY-MM-DDã€çµŒé: Nå–¶æ¥­æ—¥)ã€
    å‰å›è¨˜éŒ²ãŒç„¡ã„å ´åˆã¯ã€ŒğŸ†•åˆå›(åˆè¨˜éŒ²)ã€
    """
    tag = ""
    prev = _get_prev_hit_date(symbol)
    if prev is None:
        tag = "ğŸ†•åˆå›(åˆè¨˜éŒ²)"
    else:
        try:
            gap_bd = int(np.busday_count(prev, hit_trade_date))
        except Exception:
            gap_bd = None
        if gap_bd is not None and gap_bd >= FIRST_SEEN_BD:
            tag = f"ğŸ†•åˆå›(å‰å›: {prev.isoformat()}ã€çµŒé: {gap_bd}å–¶æ¥­æ—¥)"
    _update_last_hit(symbol, hit_trade_date)
    return tag

# ========= yfinance ãƒ˜ãƒ«ãƒ‘ =========
def _flatten_yf_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    yfinance ãŒ MultiIndex åˆ—ã‚’è¿”ã™å ´åˆã«å˜å±¤åŒ–ã™ã‚‹ã€‚
    åˆ—åã‚¿ãƒ—ãƒ«ã‹ã‚‰ 'Open','High','Low','Close','Adj Close','Volume' ã®ã„ãšã‚Œã‹ã‚’å„ªå…ˆæ¡ç”¨ã€‚
    """
    if isinstance(df.columns, pd.MultiIndex):
        keys = {"Open", "High", "Low", "Close", "Adj Close", "Volume"}
        new_cols = []
        for col in df.columns.to_list():
            chosen = None
            if isinstance(col, tuple):
                for tok in col:
                    t = str(tok)
                    if t in keys:
                        chosen = t
                        break
                if chosen is None:
                    chosen = str(col[0])
            else:
                chosen = str(col)
            new_cols.append(chosen)
        df = df.copy()
        df.columns = new_cols
    else:
        df = df.copy()
        df.columns = [str(c) for c in df.columns]

    # 'Close' ãŒç„¡ã 'Adj Close' ã®ã¿ãªã‚‰ 'Close' ã«å¯„ã›ã‚‹
    if "Close" not in df.columns and "Adj Close" in df.columns:
        df = df.rename(columns={"Adj Close": "Close"})

    # ä½™åˆ†ãªåˆ—ã¯è½ã¨ã™ï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘ï¼‰
    keep = [c for c in ["Open", "High", "Low", "Close", "Volume"] if c in df.columns]
    return df[keep]

def fetch_daily(symbol: str) -> pd.DataFrame:
    if yf is None:
        raise RuntimeError("yfinance ãŒå¿…è¦ã§ã™ï¼ˆrequirements.txt ã« yfinance ã‚’è¿½åŠ ï¼‰")

    start = (datetime.now(tz=JST) - timedelta(days=LOOKBACK_DAYS*2)).strftime("%Y-%m-%d")

    # MultiIndex ã®æºã‚Œå¯¾ç­–ã¨ã—ã¦ group_by='column' ã‚’æ˜ç¤º
    df = yf.download(
        symbol,
        start=start,
        interval="1d",
        auto_adjust=False,
        group_by="column",
        progress=False,
        threads=True,
    )
    if df is None or df.empty:
        return pd.DataFrame()

    # ãƒ•ãƒ©ãƒƒãƒˆåŒ– â†’ indexã‚’åˆ—åŒ– â†’ å°æ–‡å­—åŒ–
    df = _flatten_yf_columns(df).reset_index()
    df.columns = [str(c).lower().replace(" ", "_") for c in df.columns]

    # å¿…è¦åˆ—ã®å­˜åœ¨ç¢ºèª
    need = {"date", "open", "high", "low", "close", "volume"}
    if not need.issubset(df.columns):
        return pd.DataFrame()

    out = df[["date", "open", "high", "low", "close", "volume"]].copy()
    out["date"] = pd.to_datetime(out["date"])
    out = out.dropna(subset=["open", "high", "low", "close", "volume"]).reset_index(drop=True)
    return out

# ========= ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆ =========
def read_watchlist() -> pd.DataFrame:
    p = SCRIPT_DIR / "watchlist.csv"
    df = pd.read_csv(p)
    df.columns = [str(c).strip().lower() for c in df.columns]

    if "symbol" in df.columns:
        df["symbol"] = df["symbol"].astype(str).str.strip()
    elif "code" in df.columns:
        df["symbol"] = df["code"].astype(str).str.strip()
    else:
        raise ValueError("watchlist.csv ã« 'symbol' ã‹ 'code' åˆ—ãŒå¿…è¦ã§ã™")

    def _to_symbol(s: str) -> str:
        s = str(s).strip()
        return f"{s}.T" if s.isdigit() and not s.endswith(".T") else s

    df["symbol"] = df["symbol"].apply(_to_symbol)
    if "name" not in df.columns:
        df["name"] = df["symbol"]
    return df[["symbol", "name"]]

# ========= æŒ‡æ¨™è¨ˆç®—ãƒ»åˆ¤å®š =========
def calc_indicators(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["roc14"] = (out["close"] / out["close"].shift(ROC_PERIOD) - 1.0) * 100.0
    out["vol_ma20_prev"] = out["volume"].rolling(20).mean().shift(1)    # æ˜¨æ—¥ã¾ã§
    out["hi20_prev"]     = out["high"].rolling(20).max().shift(1)       # æ˜¨æ—¥ã¾ã§
    return out

def judge_volume_block(dfi: pd.DataFrame) -> tuple[bool, str]:
    last = dfi.iloc[-1]

    # å€ç‡æ¡ä»¶
    cond_ratio = False
    if pd.notna(last.get("vol_ma20_prev")):
        try:
            cond_ratio = float(last["volume"]) >= float(last["vol_ma20_prev"]) * VOLUME_MULT
        except Exception:
            cond_ratio = False

    # åˆ†ä½æ¡ä»¶ï¼ˆæ˜¨æ—¥ã¾ã§60æœ¬ã®åˆ†å¸ƒã§åˆ¤å®šï¼‰
    cond_quant = False
    vol_pq = float("nan")
    try:
        vol_hist = dfi["volume"].iloc[:-1].tail(60).dropna().astype(float)
        if len(vol_hist) > 0:
            vol_pq = float(np.percentile(vol_hist, VOL_QUANTILE * 100.0))
            cond_quant = float(last["volume"]) >= vol_pq
    except Exception:
        cond_quant = False

    cond_vol = (cond_ratio and cond_quant) if VOL_COND_MODE == "AND" else (cond_ratio or cond_quant)

    # å£²è²·ä»£é‡‘ã—ãã„å€¤
    if MIN_TURNOVER_JPY > 0:
        try:
            turnover = float(last["close"]) * float(last["volume"])
            cond_vol = cond_vol and (turnover >= MIN_TURNOVER_JPY)
        except Exception:
            cond_vol = False

    ratio_txt = f"MA20(prev)Ã—{VOLUME_MULT:.2f}" if pd.notna(last.get("vol_ma20_prev")) else "MA20(prev) NA"
    pq_txt = f"P{int(VOL_QUANTILE*100)}" if not np.isnan(vol_pq) else "Pq NA"
    reason = f"Vol[{VOL_COND_MODE}]: ratio({ratio_txt}) / quantile({pq_txt})"
    return cond_vol, reason

def judge_signal(dfi: pd.DataFrame) -> tuple[bool, str]:
    last = dfi.iloc[-1]
    reasons = []

    # ROC
    cond_roc = bool(pd.notna(last.get("roc14")) and last["roc14"] > 0)
    if cond_roc:
        reasons.append(f"ROC{ROC_PERIOD}>0 ({last['roc14']:.2f}%)")

    # å‡ºæ¥é«˜
    cond_vol, vol_reason = judge_volume_block(dfi)
    if cond_vol:
        reasons.append(vol_reason)

    # 20æ—¥é«˜å€¤ï¼ˆå‰æ—¥ã¾ã§ï¼‰ã‚’çµ‚å€¤ã§ãƒ–ãƒ¬ã‚¤ã‚¯
    cond_hi = bool(pd.notna(last.get("hi20_prev")) and last["close"] > last["hi20_prev"])
    if cond_hi:
        reasons.append("20d High Break (close>prev)")

    ok = bool(cond_roc and cond_vol and cond_hi)
    return ok, ", ".join(reasons)

# ========= é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ =========
def build_hit_message(symbol: str, name: str, last: pd.Series, reasons: str, header_extra: str | None = None) -> str:
    yj = f"https://finance.yahoo.co.jp/quote/{symbol}"

    # ä½“è£
    date_str = datetime.now(JST).strftime("%Y-%m-%d")
    time_str = datetime.now(JST).strftime("%H:%M")

    ma20_prev_str = f"{int(last['vol_ma20_prev']):,}" if pd.notna(last.get("vol_ma20_prev")) else "NA"

    lines = [f"ğŸ”´ ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å€™è£œ: {symbol} {name}"]
    if header_extra:
        lines.append(header_extra)

    lines += [
        f"æ—¥ä»˜: {date_str}  åˆ¤å®š: {time_str} JST",
        f"çµ‚å€¤: {float(last['close']):.2f}  ROC{ROC_PERIOD}: {float(last['roc14']):.2f}%",
        f"å‡ºæ¥é«˜: {int(last['volume']):,} / MA20(prev): {ma20_prev_str}",
        f"20då‰é«˜å€¤(å‰æ—¥ã¾ã§): {float(last['hi20_prev']):.2f}",
        f"æ¡ä»¶: {reasons}",
        f"ğŸ”— {yj}",
    ]
    return "\n".join(lines)

# ========= ãƒ¡ã‚¤ãƒ³ =========
def main():
    try:
        wl = read_watchlist()
    except Exception as e:
        notify_slack(f"[ERROR] watchlistèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    hits = 0
    for _, r in wl.iterrows():
        symbol = str(r["symbol"]).strip()
        name   = str(r["name"]).strip()
        try:
            df = fetch_daily(symbol)
            if df.empty or len(df) < 50:
                print(f"{symbol}: ãƒ‡ãƒ¼ã‚¿ãªã—/æœŸé–“ä¸è¶³")
                continue

            dfi = calc_indicators(df)
            ok, reasons = judge_signal(dfi)
            if ok:
                last = dfi.iloc[-1]
                # 'å–å¼•æ—¥'ï¼ˆ= ãƒ‡ãƒ¼ã‚¿è¡Œã®æ—¥ä»˜ï¼‰ã§ã€Œåˆå›ã€åˆ¤å®šãƒ»ä¿å­˜
                trade_date = last["date"].date()
                tag = build_first_seen_tag(symbol, trade_date)
                header_extra = tag if tag else None

                msg = build_hit_message(symbol, name, last, reasons, header_extra=header_extra)
                print(msg)
                notify_slack(msg)
                hits += 1

            time.sleep(0.2)  # API è² è·ã‚’ä¸‹ã’ã‚‹
        except Exception as e:
            print(f"{symbol}: {e}")

    if hits == 0:
        notify_slack(f"âš ï¸ {datetime.now(JST).strftime('%Y-%m-%d %H:%M')} JST ä¸€è‡´éŠ˜æŸ„ãªã—")

if __name__ == "__main__":
    try:
        main()
    except Exception:
        err = traceback.format_exc()
        print(err)
        notify_slack(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ:\n{err}")
